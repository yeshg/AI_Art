{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports and basic notebook setup\n",
    "from cStringIO import StringIO\n",
    "import numpy as np\n",
    "import os,re,random\n",
    "import scipy.ndimage as nd\n",
    "import PIL.Image\n",
    "import sys\n",
    "from IPython.display import clear_output, Image, display\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pycaffe_root = \"/home/s/caffe/python\"\n",
    "sys.path.insert(0, pycaffe_root)\n",
    "import caffe\n",
    "\n",
    "model_name = \"GoogLeNet\"\n",
    "model_path = '/home/s/caffe/models/bvlc_googlenet/'\n",
    "net_fn   = './deploy_googlenet_updated.prototxt'\n",
    "param_fn = model_path + 'bvlc_googlenet.caffemodel'\n",
    "mean = np.float32([104.0, 117.0, 123.0])\n",
    "\n",
    "net = caffe.Classifier(net_fn, param_fn,\n",
    "                       mean = mean, # ImageNet mean, training set dependent\n",
    "                       channel_swap = (2,1,0)) # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "# a couple of utility functions for converting to and from Caffe's input image layout\n",
    "def preprocess(net, img):\n",
    "    return np.float32(np.rollaxis(img, 2)[::-1]) - net.transformer.mean['data']\n",
    "def deprocess(net, img):\n",
    "    return np.dstack((img + net.transformer.mean['data'])[::-1])\n",
    "\n",
    "def blur(img, sigma):\n",
    "    if sigma > 0:\n",
    "        img[0] = nd.filters.gaussian_filter(img[0], sigma, order=0)\n",
    "        img[1] = nd.filters.gaussian_filter(img[1], sigma, order=0)\n",
    "        img[2] = nd.filters.gaussian_filter(img[2], sigma, order=0)\n",
    "    return img\n",
    "\n",
    "def bilateralFilter_and_Blur(img, sigma):\n",
    "    img[0] = cv2.bilateralFilter(nd.filters.gaussian_filter(img[0], sigma, order=0), -1, 5, 2)\n",
    "    img[1] = cv2.bilateralFilter(nd.filters.gaussian_filter(img[1], sigma, order=0), -1, 5, 2)\n",
    "    img[2] = cv2.bilateralFilter(nd.filters.gaussian_filter(img[2], sigma, order=0), -1, 5, 2)\n",
    "    return img\n",
    "\n",
    "def no_blur(img, sigma):\n",
    "    # do nothing\n",
    "    return img\n",
    "\n",
    "def showarray(a, f, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the main gradient ascent functions. Based on the [deepdream code](https://github.com/google/deepdream/blob/master/dream.ipynb) published by Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_step(net, step_size=1.5, end='inception_4c/output', clip=True, focus=None, sigma=None):\n",
    "    '''Basic gradient ascent step.'''\n",
    "\n",
    "    src = net.blobs['data'] # input image is stored in Net's 'data' blob\n",
    "    \n",
    "    dst = net.blobs[end]\n",
    "    net.forward(end=end)\n",
    "\n",
    "    one_hot = np.zeros_like(dst.data)\n",
    "    one_hot.flat[focus] = 1.\n",
    "    dst.diff[:] = one_hot\n",
    "\n",
    "    net.backward(start=end)\n",
    "    g = src.diff[0]\n",
    "    \n",
    "    src.data[:] += step_size/np.abs(g).mean() * g\n",
    "\n",
    "    if clip:\n",
    "        bias = net.transformer.mean['data']\n",
    "        src.data[:] = np.clip(src.data, -bias, 255-bias) \n",
    "    \n",
    "    # Note: All of these \n",
    "    src.data[0] = bilateralFilter_and_Blur(src.data[0], sigma)  # Approach #3 (blur + bilateralFilter)\n",
    "    # src.data[0] = blur(src.data[0], sigma)                    # Approach #3 (only blur)\n",
    "    # src.data[0] = no_blur(src.data[0], sigma)                 # Approach #2\n",
    "    \n",
    "    # reset objective for next step\n",
    "    dst.diff.fill(0.)\n",
    "\n",
    "def deepdraw(net, base_img, octaves, random_crop=True, focus=None,\n",
    "    clip=True, **step_params):\n",
    "    \n",
    "    # prepare base image\n",
    "    image = preprocess(net, base_img)\n",
    "    \n",
    "    # get input dimensions from net\n",
    "    w = net.blobs['data'].width\n",
    "    h = net.blobs['data'].height\n",
    "    \n",
    "    print \"starting drawing\"\n",
    "    src = net.blobs['data']\n",
    "    src.reshape(1,3,h,w)                                    # reshape the network's input image size\n",
    "    for e,o in enumerate(octaves):                          # scale up image if specified in octaves\n",
    "        if 'scale' in o:\n",
    "            # resize by o['scale'] if it exists\n",
    "            image = nd.zoom(image, (1,o['scale'],o['scale']))\n",
    "        _,imw,imh = image.shape\n",
    "        \n",
    "        # select layer\n",
    "        layer = o['layer']\n",
    "\n",
    "        for i in xrange(o['iter_n']):\n",
    "            if imw > w:\n",
    "                if random_crop:\n",
    "                    # randomly select a crop \n",
    "                    mid_x = (imw-w)/2.\n",
    "                    width_x = imw-w\n",
    "                    ox = np.random.normal(mid_x, width_x*0.3, 1)\n",
    "                    ox = int(np.clip(ox,0,imw-w))\n",
    "                    mid_y = (imh-h)/2.\n",
    "                    width_y = imh-h\n",
    "                    oy = np.random.normal(mid_y, width_y*0.3, 1)\n",
    "                    oy = int(np.clip(oy,0,imh-h))\n",
    "                    # insert the crop into src.data[0]\n",
    "                    src.data[0] = image[:,ox:ox+w,oy:oy+h]\n",
    "                else:\n",
    "                    ox = (imw-w)/2.\n",
    "                    oy = (imh-h)/2.\n",
    "                    src.data[0] = image[:,ox:ox+w,oy:oy+h]\n",
    "            else:\n",
    "                ox = 0\n",
    "                oy = 0\n",
    "                src.data[0] = image.copy()\n",
    "\n",
    "            sigma = o['start_sigma'] + ((o['end_sigma'] - o['start_sigma']) * i) / o['iter_n']\n",
    "            step_size = o['start_step_size'] + ((o['end_step_size'] - o['start_step_size']) * i) / o['iter_n']\n",
    "            \n",
    "            make_step(net, end=layer, clip=clip, focus=focus, \n",
    "                      sigma=sigma, step_size=step_size)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print 'finished step %d in octave %d' % (i,e)\n",
    "            \n",
    "            # insert modified image back into original image (if necessary)\n",
    "            image[:,ox:ox+w,oy:oy+h] = src.data[0]\n",
    "        \n",
    "        print \"octave %d image:\" % e\n",
    "        showarray(deprocess(net, image),\"./octave_\"+str(e)+\".jpg\")\n",
    "            \n",
    "    # returning the resulting image\n",
    "    return cv2.bilateralFilter((np.uint8(deprocess(net, image))), -1, 20, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating the class visualizations\n",
    "\n",
    "* ```layer``` : which layer to optimize\n",
    "* ```iter_n``` : how many iterations\n",
    "* ```scale``` : by what factor (if any) to scale up the base image before proceeding\n",
    "* ```start_sigma``` : the initial radius of the gaussian blur\n",
    "* ```end_sigma``` : the final radius of the gaussian blur\n",
    "* ```start_step_size``` : the initial step size of the gradient ascent\n",
    "* ```end_step_size``` : the final step size of the gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these octaves are where bulk of tuning occurs, they determine gradient ascent steps\n",
    "octaves = [\n",
    "    {\n",
    "        'layer':'loss3/classifier',   # layer to perform image updates from\n",
    "        'iter_n':190,                 # number of times to perform image update\n",
    "        'start_sigma':2.5,            # Gradually reduce gaussian blur as recommended by \n",
    "        'end_sigma':0.78,             #   https://github.com/kylemcdonald/deepdream\n",
    "        'start_step_size':11.,        # Gradually change step size of gradient ascent as recommended by \n",
    "        'end_step_size':11.           #   http://www.auduno.com/2015/07/29/visualizing-googlenet-classes/\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss3/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':150,\n",
    "        'start_sigma':0.78*1.2,\n",
    "        'end_sigma':0.78,\n",
    "        'start_step_size':6.,\n",
    "        'end_step_size':6.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss3/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':70,\n",
    "        'start_sigma':0.78*1.2,\n",
    "        'end_sigma':0.44,\n",
    "        'start_step_size':6.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss3/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':50,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss3/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':30,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss2/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':150,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss2/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':70,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss2/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':40,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss2/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':30,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss2/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':20,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss2/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':20,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss1/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':20,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss1/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':20,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss1/classifier',\n",
    "        'iter_n':30,\n",
    "        'start_sigma':0.44,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    }\n",
    "]\n",
    "\n",
    "# get original image input size from network\n",
    "original_w = net.blobs['data'].width\n",
    "original_h = net.blobs['data'].height\n",
    "# the background color of the initial image\n",
    "background_color = np.float32([28.0, 84.0, 122.0]) # This is blue\n",
    "\n",
    "for i in range(0,100): # Automate image visualization and writing to disk\n",
    "    imagenet_class = i\n",
    "    gen_image = np.random.normal(background_color, 8, (original_w, original_h, 3)) # create image of random noise with dimensions of input image\n",
    "    gen_image = deepdraw(net, gen_image, octaves, focus=imagenet_class, random_crop=True)\n",
    "    img_fn = '_'.join([model_name, \"deepdraw_denoised\", str(imagenet_class)+'.png'])\n",
    "    PIL.Image.fromarray(cv2.bilateralFilter(np.uint8(gen_image), -1, 25, 6)).save('./' + img_fn) # Very strong bilateral filter after visualization\n",
    "    # PIL.Image.fromarray(np.uint8(gen_image)).save('./' + img_fn)                               # This \"cartoonifies\" the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Less scaling and more iterations gives lower resolution but more coherent image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "octaves = [\n",
    "    {\n",
    "        'layer':'loss3/classifier',\n",
    "        'iter_n':190,\n",
    "        'start_sigma':2.5,\n",
    "        'end_sigma':0.78,\n",
    "        'start_step_size':11.,\n",
    "        'end_step_size':11.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss3/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':450,\n",
    "        'start_sigma':0.78*1.2,\n",
    "        'end_sigma':0.40,\n",
    "        'start_step_size':6.,\n",
    "        'end_step_size':3.\n",
    "    }\n",
    "]\n",
    "imagenet_class = 63\n",
    "gen_image = np.random.normal(background_color, 8, (original_w, original_h, 3))\n",
    "gen_image = deepdraw(net, gen_image, octaves, focus=imagenet_class, \n",
    "                 random_crop=True)\n",
    "\n",
    "#img_fn = '_'.join([model_name, \"deepdraw\", str(imagenet_class)+'.png'])\n",
    "#PIL.Image.fromarray(np.uint8(gen_image)).save('./' + img_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choices below give images that are not as large as in first set of automation, but are more coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "octaves = [\n",
    "    {\n",
    "        'layer':'loss3/classifier',\n",
    "        \n",
    "        'iter_n':190,\n",
    "        'start_sigma':2.5,\n",
    "        'end_sigma':0.78,\n",
    "        'start_step_size':11.,\n",
    "        'end_step_size':11.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss3/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':100,\n",
    "        'start_sigma':0.78*1.2,\n",
    "        'end_sigma':0.65,\n",
    "        'start_step_size':6.,\n",
    "        'end_step_size':6.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss2/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':90,\n",
    "        'start_sigma':0.78*1,\n",
    "        'end_sigma':0.55,\n",
    "        'start_step_size':6.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss2/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':60,\n",
    "        'start_sigma':0.78*0.8,\n",
    "        'end_sigma':0.45,\n",
    "        'start_step_size':6.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss1/classifier',\n",
    "        'scale':1.2,\n",
    "        'iter_n':10,\n",
    "        'start_sigma':0.45,\n",
    "        'end_sigma':0.304,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':3.\n",
    "    },\n",
    "    {\n",
    "        'layer':'loss1/classifier',\n",
    "        'iter_n':5,\n",
    "        'start_sigma':0.304,\n",
    "        'end_sigma':0.2,\n",
    "        'start_step_size':3.,\n",
    "        'end_step_size':1.\n",
    "    }\n",
    "]\n",
    "\n",
    "background_color = np.float32([85.0, 98.0, 112.0]) # \"Slate\" color -- tends to not work as well as blue with bilateral filter\n",
    "\n",
    "for i in range(901,1000):\n",
    "    imagenet_class = i\n",
    "    gen_image = np.random.normal(background_color, 8, (original_w, original_h, 3))\n",
    "    gen_image = deepdraw(net, gen_image, octaves, focus=imagenet_class, random_crop=True)\n",
    "    img_fn = '_'.join([model_name, \"deepdraw_denoised\", str(imagenet_class)+'.png'])\n",
    "    PIL.Image.fromarray(cv2.bilateralFilter(np.uint8(gen_image), -1, 25, 6)).save('./' + img_fn)\n",
    "    # PIL.Image.fromarray(np.uint8(gen_image)).save('./' + img_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
